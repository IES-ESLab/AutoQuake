{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c7ab431",
   "metadata": {},
   "source": [
    "# AutoQuake Demo - Complete Earthquake Catalog Generation\n",
    "\n",
    "Welcome to the AutoQuake demonstration! This notebook will guide you through the complete earthquake catalog generation workflow:\n",
    "\n",
    "1. **Download sample seismic data**\n",
    "2. **Phase Detection** with PhaseNet\n",
    "3. **Event Association** with GaMMA  \n",
    "4. **Location Refinement** with H3DD\n",
    "5. **Magnitude Calculation**\n",
    "6. **Polarity Analysis** with DiTingMotion\n",
    "7. **Focal Mechanism** with GAfocal\n",
    "\n",
    "## Prerequisites\n",
    "- AutoQuake environment activated\n",
    "- Internet connection for downloading demo data\n",
    "\n",
    "Let's generate a complete earthquake catalog! üåçüìä"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c762e6",
   "metadata": {},
   "source": [
    "## Step 1: Download Demo Data and Setup\n",
    "\n",
    "First, let's download sample seismic data and set up our working environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0344478c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç AutoQuake Complete Demo\n",
      "==================================================\n",
      "‚úÖ All AutoQuake components imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import tarfile\n",
    "import urllib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add AutoQuake to path\n",
    "sys.path.append('.')\n",
    "\n",
    "# Import AutoQuake components (following predict.py structure)\n",
    "from autoquake.picker import PhaseNet\n",
    "from autoquake.associator import GaMMA\n",
    "from autoquake.focal import GAfocal\n",
    "from autoquake.magnitude import Magnitude\n",
    "from autoquake.polarity import DitingMotion\n",
    "from autoquake.relocator import H3DD\n",
    "from autoquake.utils import pol_mag_to_dout, process_for_h3dd_twice\n",
    "\n",
    "print(\"üåç AutoQuake Complete Demo\")\n",
    "print(\"=\" * 50)\n",
    "print(\"‚úÖ All AutoQuake components imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b95a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo Configuration - Set your parameters here!\n",
    "DEMO_DATA_URL = \"https://github.com/IES-ESLab/AutoQuake/releases/download/v1.0-demo/toy_data.tgz\"\n",
    "DEMO_DATA_DIR = Path(\"./toy_data\")\n",
    "\n",
    "# Download demo data if not exists\n",
    "if not os.path.exists(DEMO_DATA_DIR):\n",
    "    print(\"üì• Downloading demo data...\")\n",
    "    try:\n",
    "        urllib.request.urlretrieve(DEMO_DATA_URL, \"toy_data.tgz\")\n",
    "        with tarfile.open(\"toy_data.tgz\", 'r:gz') as tar:\n",
    "            tar.extractall()\n",
    "        os.remove(\"toy_data.tgz\")\n",
    "        print(f\"‚úÖ Demo data extracted to '{DEMO_DATA_DIR}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        print(\"Please download manually from:\", DEMO_DATA_URL)\n",
    "else:\n",
    "    print(f\"‚úÖ Demo data already exists in '{DEMO_DATA_DIR}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3c1257",
   "metadata": {},
   "outputs": [],
   "source": [
    "NCPU = 2\n",
    "\n",
    "RESULT_DIR = Path(\"demo_results\")\n",
    "RESULT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "STATION = DEMO_DATA_DIR / \"station.csv\"\n",
    "SAC_PARENT_DIR = DEMO_DATA_DIR / \"data\"\n",
    "PZ_DIR = DEMO_DATA_DIR / \"PZ\"\n",
    "H3DD_VEL_FILE = Path(\"./H3DD/tomops_H14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ce6627",
   "metadata": {},
   "source": [
    "## Step 2: Phase Detection with PhaseNet\n",
    "\n",
    "PhaseNet is a deep learning model that automatically detects P and S wave arrivals in seismic data. This is the first step in earthquake catalog generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "183e0591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Running PhaseNet for phase detection...\n",
      "üîç Detecting earthquake phases...\n",
      "This may take a few minutes depending on data size...\n",
      "Total samples:  None\\.SAC : 0 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 0it [00:00, ?it/s]\n",
      "Predicting: 0it [00:00, ?it/s]?it/s]\n",
      "Merging 20240402: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of picks: 0\n",
      "‚ùå PhaseNet error: 'PhaseNet' object has no attribute 'picks'\n",
      "Please check your data directory and configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from ParamConfig.config_model import PhaseNetConfigReceiver\n",
    "# Step 2: Run PhaseNet (Direct approach - no pydantic)\n",
    "print(\"üöÄ Running PhaseNet for phase detection...\")\n",
    "\n",
    "phasenet_config = PhaseNetConfigReceiver(\n",
    "    data_parent_dir=SAC_PARENT_DIR,\n",
    "    start=\"20240402\",\n",
    "    end=\"20240403\",\n",
    "    result_path=RESULT_DIR,\n",
    "    pz_dir=PZ_DIR,    \n",
    ")\n",
    "# Initialize PhaseNet with direct parameters (like in predict.py)\n",
    "phasenet = PhaseNet(\n",
    "    phasenet_config\n",
    ")\n",
    "\n",
    "print(\"üîç Detecting earthquake phases...\")\n",
    "print(\"This may take a few minutes depending on data size...\")\n",
    "\n",
    "try:\n",
    "    # Run phase detection\n",
    "    phasenet.predict()\n",
    "    \n",
    "    # Get results\n",
    "    phase_picks = phasenet.get_picks()\n",
    "    print(f\"‚úÖ PhaseNet completed!\")\n",
    "    print(f\"üìä Detected {len(phase_picks)} phase picks\")\n",
    "    print(f\"   P-waves: {len(phase_picks[phase_picks['phase_type'] == 'P'])}\")\n",
    "    print(f\"   S-waves: {len(phase_picks[phase_picks['phase_type'] == 'S'])}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå PhaseNet error: {e}\")\n",
    "    print(\"Please check your data directory and configuration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969916ce",
   "metadata": {},
   "source": [
    "## Step 3: Event Association with GaMMA\n",
    "\n",
    "GaMMA (Gaussian Mixture Model Associator) groups individual phase picks into earthquake events using machine learning clustering techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33961b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phasenet_station_name_processing(pickings: Path, output_dir: Path) -> Path:\n",
    "    shutil.copy(pickings, output_dir/f\"{pickings.stem}_original.csv\")\n",
    "    df = pd.read_csv(pickings)\n",
    "    df['station_id'] = df['station_id'].map(lambda x: str(x).split('.')[1])\n",
    "    output_path = output_dir/pickings.name\n",
    "    df.to_csv(output_path, index=False)\n",
    "    return output_path\n",
    "\n",
    "# Step 3: Run GaMMA for event association\n",
    "if 'phase_picks' in locals() and len(phase_picks) > 0:\n",
    "    print(\"üîó Running GaMMA for event association...\")\n",
    "    \n",
    "    # Preprocessing for GaMMA (as in predict.py)\n",
    "    post_phasenet_pickings = phasenet_station_name_processing(\n",
    "        pickings=phase_picks,\n",
    "        output_dir=RESULT_DIR\n",
    "    )\n",
    "\n",
    "    # Initialize GaMMA with direct parameters\n",
    "    # choose number of processes: at most half of available CPUs, but not exceeding configured ncpu\n",
    "    avail_cpus = os.cpu_count() or NCPU\n",
    "    ncpu_to_use = min(max(1, avail_cpus // 2), NCPU)\n",
    "\n",
    "    gamma = GaMMA(\n",
    "        station=STATION,\n",
    "        result_path=RESULT_DIR,\n",
    "        center=(23.8, 121.0),\n",
    "        xlim_degree=[120.0, 122.5],\n",
    "        ylim_degree=[22.0, 25.5],\n",
    "        pickings=post_phasenet_pickings,\n",
    "        min_p_picks_per_eq=6,\n",
    "        min_s_picks_per_eq=2,\n",
    "        dbscan_eps=17.33,\n",
    "        ncpu=ncpu_to_use,\n",
    "        use_amplitude=False\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Run event association\n",
    "        gamma.run_predict()\n",
    "        \n",
    "        # Get results\n",
    "        gamma_events = gamma.get_events()\n",
    "        gamma_picks = gamma.get_picks()\n",
    "        \n",
    "        print(f\"‚úÖ GaMMA completed!\")\n",
    "        print(f\"üéØ Associated {len(gamma_events)} earthquake events\")\n",
    "        print(f\"üìç Average picks per event: {len(gamma_picks) / len(gamma_events):.1f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå GaMMA error: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No phase picks available. Please run PhaseNet first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5767aa4a",
   "metadata": {},
   "source": [
    "## Step 4: Location Refinement with H3DD\n",
    "\n",
    "H3DD (Hypocentroidal Decomposition Double Difference) refines earthquake locations using advanced algorithms and 3D velocity models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6b8834",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVENT_NAME = \"demo\"\n",
    "\n",
    "# Step 4: Run H3DD for location refinement (Two-step process as in predict.py)\n",
    "if 'gamma_events' in locals() and len(gamma_events) > 0:\n",
    "    print(\"Running H3DD location refinement...\")\n",
    "    \n",
    "    try:\n",
    "        # First H3DD run\n",
    "        print(\"  \udd04 H3DD first iteration...\")\n",
    "        h3dd = H3DD(\n",
    "            gamma_event=gamma_events,\n",
    "            gamma_picks=gamma_picks,\n",
    "            result_path=RESULT_DIR,\n",
    "            station=STATION,\n",
    "            model_3d=H3DD_VEL_FILE,\n",
    "            event_name=f\"{EVENT_NAME}_c0\",\n",
    "            cut_off_distance_for_dd=0.0\n",
    "        )\n",
    "        h3dd.run_h3dd()\n",
    "        \n",
    "        # Process first results for second iteration\n",
    "        print(\"  ‚öôÔ∏è  Processing first H3DD results...\")\n",
    "        h3dd_events_first, h3dd_picks_first = process_for_h3dd_twice(\n",
    "            station=STATION,\n",
    "            dout=h3dd.get_dout(),\n",
    "            event_name_1=f\"{EVENT_NAME}_c0\",\n",
    "            result_path=RESULT_DIR\n",
    "        )\n",
    "        \n",
    "        # Second H3DD run for final refinement  \n",
    "        print(\"  üîÑ H3DD second iteration...\")\n",
    "        h3dd_2 = H3DD(\n",
    "            gamma_event=h3dd_events_first,\n",
    "            gamma_picks=h3dd_picks_first,\n",
    "            result_path=RESULT_DIR,\n",
    "            station=STATION,\n",
    "            model_3d=H3DD_VEL_FILE,\n",
    "            event_name=f\"{EVENT_NAME}_c0_c2\",\n",
    "            cut_off_distance_for_dd=2.0\n",
    "        )\n",
    "        h3dd_2.run_h3dd()\n",
    "        \n",
    "        print(f\"‚úÖ H3DD completed! Refined locations for {len(h3dd_events_first)} events\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå H3DD error: {e}\")\n",
    "        print(\"Note: H3DD requires velocity models and may not work with minimal demo data\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No events available. Please run GaMMA first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e29fcb",
   "metadata": {},
   "source": [
    "## Step 5: Magnitude & Polarity Analysis\n",
    "\n",
    "Calculate earthquake magnitudes and analyze first-motion polarities for focal mechanism determination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbccca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_judge(station: str):\n",
    "    \"\"\"\n",
    "    This is designed for determining station type based on its name.\n",
    "    Typically, DAS stations start with a number, while traditional seismic stations start with a letter.\n",
    "    \"\"\"\n",
    "    return station[0].isalpha()\n",
    "\n",
    "# Step 5A: Magnitude Calculation\n",
    "if 'h3dd_2' in locals():\n",
    "    print(\"üìè Calculating earthquake magnitudes...\")\n",
    "    \n",
    "    try:\n",
    "        mag = Magnitude(\n",
    "            dout_file=h3dd_2.get_dout(),\n",
    "            station=STATION,\n",
    "            sac_parent_dir=SAC_PARENT_DIR,\n",
    "            pz_dir=PZ_DIR,\n",
    "            output_dir=RESULT_DIR,\n",
    "        )\n",
    "        mag.run_mag(processes=2)  # Use 2 processes for demo\n",
    "        \n",
    "        mag_events = mag.get_events()\n",
    "        mag_picks = mag.get_picks()\n",
    "        print(f\"‚úÖ Magnitude calculation completed for {len(mag_events)} events\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Magnitude calculation skipped: {e}\")\n",
    "        mag_events, mag_picks = None, None\n",
    "\n",
    "# Step 5B: Polarity Analysis with DiTingMotion\n",
    "if 'gamma_picks' in locals():\n",
    "    print(\"üîç Analyzing first-motion polarities...\")\n",
    "    \n",
    "    try:\n",
    "        dt_polarity = DitingMotion(\n",
    "            gamma_picks=gamma_picks,\n",
    "            output_dir=RESULT_DIR,\n",
    "            sac_parent_dir=SAC_PARENT_DIR,\n",
    "            type_judge=type_judge\n",
    "        )\n",
    "        dt_polarity.run_parallel_predict(processes=2)\n",
    "        \n",
    "        polarity_picks = dt_polarity.get_picks()\n",
    "        print(f\"‚úÖ Polarity analysis completed for {len(polarity_picks)} picks\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Polarity analysis skipped: {e}\")\n",
    "        polarity_picks = None\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No picks available for polarity analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96e023e",
   "metadata": {},
   "source": [
    "## Step 6: Focal Mechanism with GAfocal\n",
    "\n",
    "GAfocal uses genetic algorithms to determine earthquake focal mechanisms from polarity data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675b8a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Focal Mechanism Determination\n",
    "if all(var in locals() for var in ['h3dd_2', 'mag_events', 'polarity_picks']) and all(var is not None for var in [mag_events, polarity_picks]):\n",
    "    print(\"üéØ Determining focal mechanisms...\")\n",
    "    \n",
    "    try:\n",
    "        # Format data for GAfocal (combines polarity and magnitude)\n",
    "        print(\"  üìù Formatting data for focal mechanism inversion...\")\n",
    "        dout_file_name = pol_mag_to_dout(\n",
    "            ori_dout=h3dd_2.get_dout(),\n",
    "            result_path=RESULT_DIR,\n",
    "            df_reorder_event=h3dd.get_df_reorder_event(),\n",
    "            polarity_picks=polarity_picks,\n",
    "            magnitude_events=mag_events,\n",
    "            magnitude_picks=mag_picks\n",
    "        )\n",
    "        \n",
    "        # Run GAfocal genetic algorithm\n",
    "        print(\"  üß¨ Running genetic algorithm for focal mechanisms...\")\n",
    "        gafocal = GAfocal(\n",
    "            dout_file_name=dout_file_name,\n",
    "            result_path=RESULT_DIR\n",
    "        )\n",
    "        gafocal.run()\n",
    "        \n",
    "        print(\"‚úÖ Focal mechanism determination completed!\")\n",
    "        print(f\"üìä Results saved to: {RESULT_DIR}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Focal mechanism calculation skipped: {e}\")\n",
    "        print(\"This step requires complete polarity and magnitude data.\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Focal mechanism calculation skipped:\")\n",
    "    print(\"  Requires successful completion of all previous steps.\")\n",
    "    print(\"  For demo purposes, some steps may be skipped due to data limitations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a816ad64",
   "metadata": {},
   "source": [
    "## Step 7: Results Analysis & Summary\n",
    "\n",
    "Let's examine the complete earthquake catalog we've generated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac74f716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Complete Results\n",
    "print(\"üìä AutoQuake Complete Workflow Results\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Summary of all processing steps\n",
    "results_summary = {\n",
    "    'PhaseNet': len(phase_picks) if 'phase_picks' in locals() else 0,\n",
    "    'GaMMA Events': len(gamma_events) if 'gamma_events' in locals() else 0,\n",
    "    'H3DD Refined': len(h3dd_events_first) if 'h3dd_events_first' in locals() else 0,\n",
    "    'Magnitudes': len(mag_events) if 'mag_events' in locals() and mag_events is not None else 0,\n",
    "    'Polarities': len(polarity_picks) if 'polarity_picks' in locals() and polarity_picks is not None else 0\n",
    "}\n",
    "\n",
    "for step, count in results_summary.items():\n",
    "    status = \"‚úÖ\" if count > 0 else \"‚ö†Ô∏è\"\n",
    "    print(f\"{status} {step}: {count}\")\n",
    "\n",
    "# Check output files\n",
    "print(\"\\nüìÅ Generated Files:\")\n",
    "for file_path in RESULT_DIR.glob(\"*\"):\n",
    "    if file_path.is_file():\n",
    "        size_mb = file_path.stat().st_size / (1024*1024)\n",
    "        print(f\"  üìÑ {file_path.name} ({size_mb:.2f} MB)\")\n",
    "\n",
    "# Create summary visualization if we have results\n",
    "if 'phase_picks' in locals() and len(phase_picks) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('AutoQuake Complete Workflow Results', fontsize=16)\n",
    "    \n",
    "    # Plot 1: Workflow progress\n",
    "    steps = list(results_summary.keys())\n",
    "    counts = list(results_summary.values())\n",
    "    axes[0, 0].bar(range(len(steps)), counts)\n",
    "    axes[0, 0].set_title('Processing Pipeline Results')\n",
    "    axes[0, 0].set_xticks(range(len(steps)))\n",
    "    axes[0, 0].set_xticklabels(steps, rotation=45)\n",
    "    axes[0, 0].set_ylabel('Count')\n",
    "    \n",
    "    # Plot 2: Phase picks timeline\n",
    "    if len(phase_picks) > 0:\n",
    "        phase_picks['phase_time_dt'] = pd.to_datetime(phase_picks['phase_time'])\n",
    "        phase_picks.set_index('phase_time_dt').resample('H').size().plot(ax=axes[0, 1])\n",
    "        axes[0, 1].set_title('Phase Detections Over Time')\n",
    "        axes[0, 1].set_ylabel('Number of Picks')\n",
    "    \n",
    "    # Plot 3: Event locations (if available)\n",
    "    if 'gamma_events' in locals() and len(gamma_events) > 0:\n",
    "        axes[1, 0].scatter(gamma_events['longitude'], gamma_events['latitude'], \n",
    "                          c=gamma_events['depth_km'], cmap='viridis_r', s=50)\n",
    "        axes[1, 0].set_title('Earthquake Locations')\n",
    "        axes[1, 0].set_xlabel('Longitude')\n",
    "        axes[1, 0].set_ylabel('Latitude')\n",
    "        \n",
    "    # Plot 4: Magnitude distribution (if available)\n",
    "    if 'mag_events' in locals() and mag_events is not None and len(mag_events) > 0:\n",
    "        axes[1, 1].hist(mag_events['magnitude'], bins=10, alpha=0.7)\n",
    "        axes[1, 1].set_title('Magnitude Distribution')\n",
    "        axes[1, 1].set_xlabel('Magnitude')\n",
    "        axes[1, 1].set_ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nüéâ AutoQuake Demo Completed!\")\n",
    "print(\"\\nüìö Next Steps:\")\n",
    "print(\"  ‚Ä¢ Modify parameters above to experiment with different settings\")\n",
    "print(\"  ‚Ä¢ Use your own seismic data following the directory structure\")\n",
    "print(\"  ‚Ä¢ Explore individual result files for detailed analysis\")\n",
    "print(\"  ‚Ä¢ Check the AutoQuake documentation for advanced features\")\n",
    "print(\"\\nüí° Tips:\")\n",
    "print(\"  ‚Ä¢ Larger datasets will produce more reliable results\")\n",
    "print(\"  ‚Ä¢ Each step builds on the previous - ensure clean data flow\")\n",
    "print(\"  ‚Ä¢ Some steps may be skipped in demo due to data/model limitations\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoQuake_v0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
