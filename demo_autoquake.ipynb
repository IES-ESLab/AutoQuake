{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c7ab431",
   "metadata": {},
   "source": [
    "## AutoQuake Demo - Complete Earthquake Catalog Generation\n",
    "---\n",
    "***Welcome to the AutoQuake demonstration!***     \n",
    "***This notebook will guide you through the complete earthquake catalog generation workflow:***\n",
    "\n",
    "1. **Download sample seismic data**\n",
    "\n",
    "2. **Phase Detection** with `PhaseNet`\n",
    "3. **Event Association** with `GaMMA` \n",
    "4. **Relocation** with `H3DD`\n",
    "5. **Magnitude Estimation** with CWA standard\n",
    "6. **Polarity Determination** with `DiTingMotion`\n",
    "7. **Focal Mechanism** with `GAfocal`\n",
    "\n",
    "### ***Prerequisites***\n",
    "- Install the conda environment (`conda env create -f env.yml`), and select it for kernel\n",
    "\n",
    "- Internet connection for downloading demo data\n",
    "- Compile the H3DD and GAFocal\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c762e6",
   "metadata": {},
   "source": [
    "### ***Step 1: Download Demo Data and Setup***\n",
    "\n",
    "First, let's download sample seismic data and import necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0344478c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All AutoQuake components imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import tarfile\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add AutoQuake to path\n",
    "sys.path.append('.')\n",
    "\n",
    "# Import AutoQuake components (following predict.py structure)\n",
    "from autoquake.picker import PhaseNet, run_predict\n",
    "from autoquake.associator import GaMMA\n",
    "from autoquake.focal import GAfocal\n",
    "from autoquake.magnitude import Magnitude\n",
    "from autoquake.polarity import DitingMotion\n",
    "from autoquake.relocator import H3DD\n",
    "from autoquake.utils import pol_mag_to_dout\n",
    "\n",
    "from ParamConfig.config_model import PhaseNetConfigReceiver\n",
    "\n",
    "print(\"All AutoQuake components imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b95a3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded!\n",
      "Demo data extracted to 'toy_data'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Demo Configuration - Set your parameters here!\n",
    "record_id = \"17470233\"\n",
    "filename = \"toy_data.tgz\"\n",
    "\n",
    "DEMO_DATA_URL = f\"https://zenodo.org/records/{record_id}/files/{filename}?download=1\"\n",
    "DEMO_DATA_DIR = Path(\"./toy_data\")\n",
    "DEMO_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    response = requests.get(DEMO_DATA_URL, stream=True, timeout=60)\n",
    "    with open(DEMO_DATA_DIR / filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(\"Downloaded!\")\n",
    "\n",
    "    with tarfile.open(DEMO_DATA_DIR / filename, 'r:gz') as tar:\n",
    "        # Get all members and strip the first directory level\n",
    "        for member in tar.getmembers():\n",
    "            # Skip the root 'toy_data/' directory itself\n",
    "            if member.name == 'toy_data' or member.name == 'toy_data/':\n",
    "                continue            \n",
    "            if member.name.startswith('toy_data/'):\n",
    "                member.name = member.name.replace('toy_data/', '', 1)  # Remove first 'toy_data/'\n",
    "            tar.extract(member, DEMO_DATA_DIR)\n",
    "    print(f\"Demo data extracted to '{DEMO_DATA_DIR}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Please download manually from:\", DEMO_DATA_URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f3c1257",
   "metadata": {},
   "outputs": [],
   "source": [
    "NCPU = 2\n",
    "\n",
    "RESULT_DIR = Path(\"demo_results\")\n",
    "RESULT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "STATION = DEMO_DATA_DIR / \"station.csv\"\n",
    "SAC_PARENT_DIR = DEMO_DATA_DIR / \"data\"\n",
    "PZ_DIR = DEMO_DATA_DIR / \"PZ\"\n",
    "H3DD_VEL_FILE = Path(\"./H3DD/tomops_H14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ce6627",
   "metadata": {},
   "source": [
    "### ***Step 2: Phase Detection with PhaseNet***\n",
    "\n",
    "PhaseNet is a deep learning model that automatically detects P and S wave arrivals in seismic data. This is the first step in earthquake catalog generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e0591",
   "metadata": {},
   "outputs": [],
   "source": [
    "phasenet_config = PhaseNetConfigReceiver(\n",
    "    data_parent_dir=SAC_PARENT_DIR,\n",
    "    start=\"20240402\",\n",
    "    end=\"20240404\",\n",
    "    result_path=RESULT_DIR,\n",
    "    pz_dir=PZ_DIR,\n",
    "    min_prob=0.5  \n",
    ")\n",
    "\n",
    "run_predict(phasenet_config.args_list)\n",
    "\n",
    "phase_picks = PhaseNet.concat_picks(\n",
    "    date_list=['20240402', '20240403'],\n",
    "    result_path=RESULT_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969916ce",
   "metadata": {},
   "source": [
    "### ***Step 3: Event Association with GaMMA***\n",
    "\n",
    "GaMMA (Gaussian Mixture Model Associator) groups individual phase picks into earthquake events using machine learning clustering techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a33961b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting 2550 picks using eps=14.44\n",
      "Splitting 2086 picks using eps=14.44\n",
      "Splitting 1382 picks using eps=14.44\n",
      "Splitting 2246 picks using eps=12.03\n",
      "Splitting 2082 picks using eps=12.03\n",
      "Associating 135 clusters with 40 CPUs\n",
      ".......................................................................................................................................\n",
      "Associated 100 events\n",
      "\n",
      "Associated 200 events\n"
     ]
    }
   ],
   "source": [
    "def phasenet_station_name_processing(pickings: Path, output_dir: Path) -> Path:\n",
    "    shutil.copy(pickings, output_dir/f\"{pickings.stem}_original.csv\")\n",
    "    df = pd.read_csv(pickings)\n",
    "    df['station_id'] = df['station_id'].map(lambda x: str(x).split('.')[1])\n",
    "    output_path = output_dir/pickings.name\n",
    "    df.to_csv(output_path, index=False)\n",
    "    return output_path\n",
    "\n",
    "# Preprocessing for GaMMA (as in predict.py)\n",
    "post_phasenet_pickings = phasenet_station_name_processing(\n",
    "    pickings=Path(\"/home/patrick/Work/AutoQuake/demo_results/picks_phasenet/picks.csv\"),\n",
    "    output_dir=RESULT_DIR\n",
    ")\n",
    "\n",
    "# Initialize GaMMA with direct parameters\n",
    "# choose number of processes: at most half of available CPUs, but not exceeding configured ncpu\n",
    "avail_cpus = os.cpu_count() or NCPU\n",
    "ncpu_to_use = min(max(1, avail_cpus // 2), NCPU)\n",
    "\n",
    "gamma = GaMMA(\n",
    "    station=STATION,\n",
    "    result_path=RESULT_DIR,\n",
    "    center=(121.625, 24.0),\n",
    "    xlim_degree=[121.0, 122.25],\n",
    "    ylim_degree=[23.25, 24.75],\n",
    "    pickings=post_phasenet_pickings,\n",
    "    min_p_picks_per_eq=6,\n",
    "    min_s_picks_per_eq=2,\n",
    "    dbscan_eps=17.33,\n",
    "    ncpu=ncpu_to_use,\n",
    "    use_amplitude=False\n",
    ")\n",
    "\n",
    "# Run event association\n",
    "gamma.run_predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5767aa4a",
   "metadata": {},
   "source": [
    "### ***Step 4: Relocation with H3DD***\n",
    "\n",
    "Relocation with Hypo-DD strengthen by 3D velocity models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6b8834",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running H3DD...\")\n",
    "h3dd = H3DD(\n",
    "    gamma_event=gamma.get_events(),\n",
    "    gamma_picks=gamma.get_picks(),\n",
    "    result_path=RESULT_DIR,\n",
    "    station=STATION,\n",
    "    model_3d=H3DD_VEL_FILE,\n",
    "    event_name=\"demo_c0\",\n",
    "    cut_off_distance_for_dd=0.0\n",
    ")\n",
    "h3dd.run_h3dd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e29fcb",
   "metadata": {},
   "source": [
    "### ***Step 5: Magnitude Estimation***\n",
    "\n",
    "Calculate earthquake magnitudes with **regional specific magnitude empirical formula**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbccca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag = Magnitude(\n",
    "    dout_file=h3dd.get_dout(),\n",
    "    station=STATION,\n",
    "    sac_parent_dir=SAC_PARENT_DIR,\n",
    "    pz_dir=PZ_DIR,\n",
    "    output_dir=RESULT_DIR,\n",
    ")\n",
    "mag.run_mag(processes=2)  # Use 2 processes for demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b3b750",
   "metadata": {},
   "source": [
    "### ***Step 6: DiTingMotion - Polarity determination***\n",
    "\n",
    "Analyze first-motion polarities for focal mechanism determination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b32c3be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_judge(station: str):\n",
    "    \"\"\"\n",
    "    This is designed for determining station type based on its name.\n",
    "    Typically, DAS stations start with a number, while traditional seismic stations start with a letter.\n",
    "    \"\"\"\n",
    "    return station[0].isalpha()\n",
    "\n",
    "dt_polarity = DitingMotion(\n",
    "    gamma_picks=gamma.get_picks(),\n",
    "    output_dir=RESULT_DIR,\n",
    "    sac_parent_dir=SAC_PARENT_DIR,\n",
    "    type_judge=type_judge\n",
    ")\n",
    "dt_polarity.run_parallel_predict(processes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96e023e",
   "metadata": {},
   "source": [
    "### ***Step 7: Focal Mechanism with GAfocal***\n",
    "\n",
    "GAfocal uses genetic algorithms to determine earthquake focal mechanisms from polarity data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675b8a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dout_file_name = pol_mag_to_dout(\n",
    "    ori_dout=h3dd.get_dout(),\n",
    "    result_path=RESULT_DIR,\n",
    "    gamma_event=gamma.get_events(),\n",
    "    polarity_picks=dt_polarity.get_picks(),\n",
    "    magnitude_events=mag.get_events(),\n",
    "    magnitude_picks=mag.get_picks()\n",
    ")\n",
    "\n",
    "# Run GAfocal genetic algorithm\n",
    "print(\"Running genetic algorithm for focal mechanisms...\")\n",
    "gafocal = GAfocal(\n",
    "    dout_file_name=dout_file_name,\n",
    "    result_path=RESULT_DIR\n",
    ")\n",
    "gafocal.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a2554d",
   "metadata": {},
   "source": [
    "---\n",
    "### ***Visualization***\n",
    "\n",
    "Here we simply display the beachball on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc5f154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LightSource\n",
    "\n",
    "import pygmt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.geoaxes import GeoAxes\n",
    "\n",
    "from pyrocko import moment_tensor as pmt\n",
    "from pyrocko.plot import beachball, mpl_color\n",
    "\n",
    "def check_hms_gafocal(hms: str):\n",
    "    \"\"\"\n",
    "    check whether the gafocal format's second overflow\n",
    "    \"\"\"\n",
    "    minute = int(hms[3:5])\n",
    "    second = int(hms[6:8])\n",
    "\n",
    "    if second >= 60:\n",
    "        minute += second // 60\n",
    "        second = second % 60\n",
    "\n",
    "    fixed_hms = hms[:3] + f'{minute:02d}' + hms[5:6] + f'{second:02d}'\n",
    "    return fixed_hms\n",
    "\n",
    "def txt_preprocessor(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[1] = df[1].apply(check_hms_gafocal)\n",
    "    df['time'] = df[0].apply(lambda x: x.replace('/', '-')) + 'T' + df[1]\n",
    "    for col in [6, 8, 10]:\n",
    "        df[col] = df[col].map(lambda x: int(x.split('+')[0]))\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            2: 'longitude',\n",
    "            3: 'latitude',\n",
    "            4: 'depth_km',\n",
    "            5: 'magnitude',\n",
    "            6: 'strike',\n",
    "            7: 'strike_err',\n",
    "            8: 'dip',\n",
    "            9: 'dip_err',\n",
    "            10: 'rake',\n",
    "            11: 'rake_err',\n",
    "            12: 'quality_index',\n",
    "            13: 'num_of_polarity',\n",
    "        }\n",
    "    )\n",
    "    mask = [i for i in df.columns.tolist() if isinstance(i, str)]\n",
    "    df = df[mask]\n",
    "    return df\n",
    "\n",
    "def read_gafocal(gafocal_txt: str | Path) -> pd.DataFrame:   \n",
    "    df = pd.read_csv(\n",
    "        gafocal_txt,\n",
    "        sep=r'\\s+',\n",
    "        header=None,\n",
    "        dtype={0: 'str', 1: 'str'},\n",
    "    )\n",
    "    df = txt_preprocessor(df)    \n",
    "    return df\n",
    "\n",
    "def get_mapview(\n",
    "    region: list,\n",
    "    ax: GeoAxes,\n",
    "    cmap='gray',\n",
    "    hillshade=True,\n",
    "    resolution='15s',\n",
    "    vert_exag=10,\n",
    "    ):\n",
    "    # from matplotlib.colors import ListedColormap\n",
    "    \"\"\"## Plotting the basic map.\n",
    "\n",
    "    Notice here, the ax should be a GeoAxes! A subclass of `matplotlib.axes.Axes`.\n",
    "    \"\"\"\n",
    "    topo = (\n",
    "        pygmt.datasets.load_earth_relief(resolution=resolution, region=region).to_numpy()\n",
    "        / 1e3\n",
    "    )  # km\n",
    "    x = np.linspace(region[0], region[1], topo.shape[1])\n",
    "    y = np.linspace(region[2], region[3], topo.shape[0])\n",
    "    xgrid, ygrid = np.meshgrid(x, y)\n",
    "    ls = LightSource(azdeg=0, altdeg=45)\n",
    "\n",
    "    ax.pcolormesh(\n",
    "        xgrid,\n",
    "        ygrid,\n",
    "        ls.hillshade(topo, vert_exag=vert_exag, dx=1, dy=1) if hillshade else topo,\n",
    "        vmin=-1 if hillshade else None,\n",
    "        shading='gouraud',\n",
    "        cmap=cmap,\n",
    "        alpha=1.0,\n",
    "        antialiased=True,\n",
    "        rasterized=True,\n",
    "    )\n",
    "\n",
    "    # cartopy setting\n",
    "    ax.coastlines()\n",
    "    ax.set_extent(region)\n",
    "\n",
    "    gl = ax.gridlines(draw_labels=True)\n",
    "    gl.top_labels = False  # Turn off top labels\n",
    "    gl.right_labels = False  # Turn off top labels\n",
    "    gl.xlabel_style = {\n",
    "        'weight': 'bold',\n",
    "        'size': 10\n",
    "    }\n",
    "    gl.ylabel_style = {\n",
    "        'rotation': 90,\n",
    "        'weight': 'bold',\n",
    "        'size': 10\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db49252",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_gafocal(RESULT_DIR / \"gafocal_results.txt\")\n",
    "df_station = pd.read_csv(STATION)\n",
    "\n",
    "region = [\n",
    "    float(df['longitude'].min()) - 0.2,\n",
    "    float(df['longitude'].max()) + 0.1,\n",
    "    float(df['latitude'].min()) - 0.1,\n",
    "    float(df['latitude'].max()) + 0.1\n",
    "]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 18))    \n",
    "geo_ax = fig.add_subplot(projection=ccrs.PlateCarree())\n",
    "get_mapview(\n",
    "    region=region,\n",
    "    ax=geo_ax,\n",
    ")\n",
    "geo_ax.set_xlim(region[0], region[1])\n",
    "geo_ax.set_ylim(region[2], region[3])\n",
    "# Station\n",
    "geo_ax.scatter(\n",
    "    df_station['longitude'],\n",
    "    df_station['latitude'],\n",
    "    s=50,\n",
    "    c='c',\n",
    "    marker='^',\n",
    "    edgecolors='k',\n",
    "    alpha=0.7,\n",
    "    rasterized=True,\n",
    "    label='Seismometer',\n",
    "    zorder=4,\n",
    ")\n",
    "# geo_ax.set_aspect('auto')\n",
    "\n",
    "for i, row in enumerate(df.itertuples()):\n",
    "    mt = pmt.MomentTensor(\n",
    "        strike=row.strike,\n",
    "        dip=row.dip,\n",
    "        rake=row.rake,\n",
    "    )\n",
    "    beachball.plot_beachball_mpl(\n",
    "        mt, geo_ax, size=20, beachball_type='full',\n",
    "        position=(row.longitude, row.latitude), linewidth=1,\n",
    "        color_t=mpl_color('k'),\n",
    "        zorder=9\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoQuake_v0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
